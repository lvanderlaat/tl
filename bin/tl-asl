#!/usr/bin/env python


"""
Amplitude source location
"""


# Python Standard Library
import os

from itertools import repeat
from linecache import getline

# Other dependencies
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tl

try:
    import ray.util.multiprocessing as multiprocessing
except:
    import multiprocessing

from numba import jit

# Local files


__author__ = 'Leonardo van der Laat'
__email__  = 'laat@umich.edu'


@jit(nopython=True)
def locate(Q, alpha, beta, f, a, x, y, z, xxx, yyy, zzz):
    B = np.pi*f/Q/beta

    res = np.zeros(xxx.shape)

    n_stations = len(a)

    for i in range(n_stations-1):
        d_i = np.sqrt((xxx-x[i])**2 + (yyy-y[i])**2 + (zzz-z[i])**2)
        for j in range(i+1, n_stations):
            d_j = np.sqrt((xxx-x[j])**2 + (yyy-y[j])**2 + (zzz-z[j])**2)

            r_obs = a[i]/a[j]

            r_calc = (np.exp(-B*d_i)/d_i**alpha) / (np.exp(-B*d_j)/d_j**alpha)

            res += (r_calc - r_obs)**2
    return np.sqrt(res)


def work(
    Q, alpha, beta, f, a, x, y, z, xmin, xmax, ymin, ymax, zmin, zmax, cellsize
):
    # Create grid
    xxx, yyy, zzz = np.meshgrid(
        np.arange(xmin, xmax+cellsize, cellsize),
        np.arange(ymin, ymax+cellsize, cellsize),
        np.arange(zmin, zmax+cellsize, cellsize)
    )

    try:
        res = locate(Q, alpha, beta, f, a, x, y, z, xxx, yyy, zzz)
        idx = np.unravel_index(res.argmin(), res.shape)
        loc = np.array([xxx[idx], yyy[idx], zzz[idx]])
        print(loc)
        return loc, res[idx]
    except:
        return np.full(3, np.nan), np.nan


def main():
    # Parse arguments
    args = tl.utils.parse_args()

    # Parse configuration YAML file
    c = tl.config.read(args.configfile)

    # Load amplitude data
    df = pd.read_csv(c.asl.data_csv)

    # Output folder directory
    folderpath = tl.utils.create_folder(c.io.output_dir, f'ASL', c.io.overwrite)
    tl.utils.write_conf(c, folderpath)

    # Channels
    channels = pd.read_csv(c.amplitude.channels_csv, comment='/')
    channels = channels[channels.channel.str[-1] == 'Z']
    channels.reset_index(inplace=True)

    # features metadata
    meta = tl.features.to_dataframe(channels, c.amplitude.bands)

    # Read metadata
    meta = pd.read_csv(c.asl.meta_csv)
    meta = meta[
        (meta.freqmin == c.asl.band[0]) & (meta.freqmax == c.asl.band[1])
    ]

    xmin = channels.x.min() - 2*c.asl.cellsize
    xmax = channels.x.max() + 2*c.asl.cellsize
    ymin = channels.y.min() - 2*c.asl.cellsize
    ymax = channels.y.max() + 2*c.asl.cellsize

    # Correct site effect
    for i, row in meta.iterrows():
        df[row.key] /= row.cf

    args_parallel = zip(
        repeat(c.attenuation.Q), repeat(c.attenuation.alpha),
        repeat(c.attenuation.beta), repeat(c.attenuation.f),
        df[meta.key].values,
        repeat(meta.x.values), repeat(meta.y.values), repeat(meta.z.values),
        repeat(xmin), repeat(xmax),
        repeat(ymin), repeat(ymax),
        repeat(c.asl.zmin), repeat(c.asl.zmax),
        repeat(c.asl.cellsize)
    )
    with multiprocessing.Pool(c.performance.max_workers) as pool:
        results = pool.starmap(work, args_parallel)

    locs, res = list(map(list, zip(*results)))
    locs = np.array(locs)

    out = pd.DataFrame(locs, columns='x y z'.split())
    out['res'] = res
    out['eventid'] = df.eventid

    out.to_csv(os.path.join(folderpath, 'locs.csv'), index=False)
    return


if __name__ == '__main__':
    main()
