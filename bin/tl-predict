#!/usr/bin/env python


"""
Predict tremor locations
"""


# Python Standard Library
import os
import pickle
import warnings

# Other dependencies
import numpy as np
import pandas as pd

from sklearn.impute import SimpleImputer

# Local files
import tl


__author__ = 'Leonardo van der Laat'
__email__  = 'laat@umich.edu'


def main():
    # Parse arguments
    args = tl.utils.parse_args()

    # Logger
    logger = tl.utils.get_logger()

    # Get configuration
    c = tl.config.read(args.configfile)

    # Create output folder
    folderpath = tl.utils.create_folder(c.io.output_dir, 'LOCS', c.io.overwrite)

    # Load model and scaler
    with open(os.path.join(c.predict.model_dir, 'scaler_X.pkl'), 'rb') as f:
        scaler_X = pickle.load(f)
    with open(os.path.join(c.predict.model_dir, 'scaler_y.pkl'), 'rb') as f:
        scaler_y = pickle.load(f)
    with open(os.path.join(c.predict.model_dir, 'model.pkl'), 'rb') as f:
        model = pickle.load(f)

    # Load metadata
    channels = pd.read_csv(c.amplitude.channels_csv, comment='/')
    meta = tl.features.to_dataframe(channels, c.amplitude.bands)
    df   = pd.read_csv(
        c.predict.data_file, index_col='datetime', parse_dates=['datetime']
    )

    # Feature engineering
    logger.info('Feature engineering...')
    metadata, features = tl.features.engineer(
        df, meta,
        c.engineer.ratio_same_station,
        c.engineer.ratio_diff_bands,
        c.engineer.transformations,
        c.performance.max_workers
    )

    logger.info(f'{len(metadata)} features')

    # To NumPy arrays for SciKit-Learn
    features.replace([np.inf, -np.inf], np.nan, inplace=True)

    X = features[metadata.key].values

    # Impute NaN values
    logger.info('Imputing NaN values')
    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')
    X = imputer.fit_transform(X)

    # Standarize data
    X = scaler_X.transform(X)

    # Predict
    y = model.predict(X)

    y = scaler_y.inverse_transform(y)

    df['x'] = y[:, 0]
    df['y'] = y[:, 1]
    df['z'] = y[:, 2]

    df = df['x y z'.split()]
    df.to_csv(os.path.join(folderpath, 'locs.csv'))

    sta = channels.drop_duplicates(subset='station')

    fig = tl.plot.locations(df, sta, s=1)
    fig.savefig(os.path.join(folderpath, 'locs.pdf'), dpi=300)

    fig = tl.plot.loc_timeseries(df)
    fig.savefig(os.path.join(folderpath, 'locs_timeseries.pdf'), dpi=300)

    tl.utils.write_conf(c, folderpath)
    return


if __name__ == '__main__':
    warnings.filterwarnings('ignore')
    main()
